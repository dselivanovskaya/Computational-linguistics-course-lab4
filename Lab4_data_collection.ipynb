{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1471594d",
   "metadata": {},
   "source": [
    "# Lab4 data collection\n",
    "## By Evgeny Melnikov\n",
    "\n",
    "The code below extracts Vladimir Mayakovsky's poems from https://www.culture.ru and writes them down to a json file alongside poems' titles, tags, etc.\n",
    "\n",
    "In addition, all the poems are concatenated in a single file, which will be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "13f06a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "from time import sleep\n",
    "# import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import unicodedata\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from html2text import html2text\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "50b3a66f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The function extracts poems from https://www.culture.ru/literature/poems\n",
    "# and writes them in JSON format to out_filename\n",
    "# The extracted data is: \n",
    "# - poem link\n",
    "# - poem title \n",
    "# - poem author\n",
    "# - poem tags \n",
    "# - poem text\n",
    "# The number of pages the poems are extracted from is specified by page_num\n",
    "# The author is specified by author_name \n",
    "\n",
    "def parse_cultureru_poems(author_name, page_num, out_filename, progress_bar=True):   \n",
    "    domain_name = \"https://www.culture.ru\"\n",
    "    \n",
    "    # progress bar setup   \n",
    "    if progress_bar:\n",
    "        page_bar = tqdm(range(page_num), desc = 'Page progress', leave = False)\n",
    "\n",
    "    # create output json file\n",
    "    with open(out_filename,'w', encoding=\"utf-8\") as file:\n",
    "        pass   \n",
    "    \n",
    "    # convert the author_name string to use it when constructing links\n",
    "    author_name = author_name.replace(\" \", \"-\")\n",
    "    author_name = author_name.lower()    \n",
    "    \n",
    "    # iterate over pages of all author's poems\n",
    "    for page in range(1, page_num + 1):\n",
    "        \n",
    "        if progress_bar:\n",
    "            page_bar.update(1)\n",
    "        \n",
    "        previews_link = f\"{domain_name}/literature/poems/author-{author_name}?page={page}\" # construct a link\n",
    "        soup = BeautifulSoup(requests.get(previews_link, verify=False).text, \"lxml\")\n",
    "        \n",
    "        poem_previews = soup.find_all(\"div\", {\"class\": \"eWEZx\"}) # divs containing preview of a poem\n",
    "        for poem_preview in poem_previews: # iterate over poem previews\n",
    "            poem_rel_link = poem_preview.find(\"a\", {\"class\": \"C0Urp\"})['href'] # find a relative link to a poem in a div \n",
    "            poem_link = domain_name + poem_rel_link # construct an absolute link            \n",
    "            soup_poem = BeautifulSoup(requests.get(poem_link, verify=False).text, \"lxml\") # get a page with a poem            \n",
    "            # суп поем лол\n",
    "            \n",
    "            # exctract poem data            \n",
    "            json_dict = {} # create a dictionary for poem data\n",
    "            json_dict['link'] = poem_link\n",
    "            \n",
    "            title = soup_poem.find(\"div\", {\"class\": \"kNLyi\"}).getText(' ').strip() # div containing a poem title\n",
    "            json_dict['title'] = unicodedata.normalize(\"NFKD\", title) # thereafter, .normalize is used to remove '\\xa0' characters\n",
    "            \n",
    "            author = soup_poem.find(\"div\", {\"class\": \"_5bAYe\"}).getText(' ').strip() # div containing author's name\n",
    "            json_dict['author'] = unicodedata.normalize(\"NFKD\", author)\n",
    "            \n",
    "            # text processing\n",
    "            poem_text = soup_poem.find(\"div\", {\"class\": \"xiryu\"}) # div containing the poem itself \n",
    "            poem_text = poem_text.find_all(\"p\") # find all paragraphs\n",
    "            poem_text = [paragraph.getText('\\n') for paragraph in poem_text] # list of paragraphs            \n",
    "            poem_text = '\\n'.join(poem_text) # join a list of paragraphs into a single string            \n",
    "            poem_text = unicodedata.normalize(\"NFKD\", poem_text)\n",
    "            # poem_text = re.sub(\"[\\d+]\\.\", ' ', poem_text) # remove digits with periods (like \"2.\")\n",
    "            # poem_text = re.sub(\"[\\d]\", ' ', poem_text) # remove all the other digits\n",
    "            # actually, it'a crutch. I'm too lazy to learn regexes right now, so deal with it s\n",
    "            # poem_text = re.sub(' +', ' ', poem_text) # remove multiple spaces         \n",
    "            poem_text = poem_text.strip() # strip one more time 'cause why not :) \n",
    "            json_dict['text'] = poem_text\n",
    "           \n",
    "            # tags processing\n",
    "            json_dict['tags'] = []\n",
    "            poem_tags = soup_poem.find_all(\"div\", {\"class\": \"zUOzO\"}) # div containing a tag\n",
    "            for tag in poem_tags:\n",
    "                json_dict['tags'].append(unicodedata.normalize(\"NFKD\", tag.getText(' ').strip()))\n",
    "                \n",
    "            # write data to output json file  \n",
    "            with open(out_filename,'a', encoding=\"utf-8\") as file:\n",
    "                file.write(json.dumps(json_dict, ensure_ascii=False) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "e35ecaf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff333626a3714b0f89478df73911deae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Page progress:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parse_cultureru_poems(author_name=\"Vladimir Mayakovskii\", page_num=29, out_filename=\"Poems2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "fc3e0e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate(json_filename, out_filename):\n",
    "    data = pd.read_json(json_filename, lines=True)\n",
    "    all_poems = [poem + '\\n\\n'  for poem in data['text']]\n",
    "    \n",
    "    with open(out_filename,'w', encoding=\"utf-8\") as file:\n",
    "        file.write(' '.join(all_poems))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a6c95452",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate(\"Poems.json\", \"all_poems2.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
